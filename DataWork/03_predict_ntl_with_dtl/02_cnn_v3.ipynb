{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "02_cnn_v3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BKpl1aUCSEq"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgMAnmidCSEq"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMauiVIOCSEr"
      },
      "source": [
        "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "# https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
        "\n",
        "from numpy.random import seed\n",
        "\n",
        "\n",
        "import os, datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import re \n",
        "\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, Model\n",
        "from keras import models\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model, Model\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import tensorflow.keras as K\n",
        "\n",
        "import logging, os \n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import config as cf\n",
        "\n",
        "# Set seeds. Note that using a GPU can still introduce randomness.\n",
        "# (also not taking into account tensorflow randomness)\n",
        "seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f04J5mQCSEr"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Fvz7flCSEs"
      },
      "source": [
        "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
        "\n",
        "class DataGenerator(keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), n_channels=1,\n",
        "                 n_classes=10, shuffle=True):\n",
        "        'Initialization'\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.labels = labels\n",
        "        self.list_IDs = list_IDs\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.list_IDs))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples' \n",
        "        \n",
        "        # Initialization\n",
        "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
        "        y = np.empty((self.batch_size)) # dtype=int \n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            X[i,] = np.load(os.path.join(NPY_PATH, ID + '.npy'))\n",
        "\n",
        "            # Store class\n",
        "            y[i] = self.labels[ID]\n",
        "        \n",
        "        return X, to_categorical(y, num_classes=self.n_classes)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CEnTeiXCSEs"
      },
      "source": [
        "def define_model_imagenet(height, width, num_classes):\n",
        "    '''\n",
        "    Defines and compiles CNN model.\n",
        "    \n",
        "    Inputs:\n",
        "        height, width, channels, num_classes (int)\n",
        "    Returns:\n",
        "        model (keras.Model object)\n",
        "    '''\n",
        "\n",
        "    # https://medium.com/abraia/first-steps-with-transfer-learning-for-custom-image-classification-with-keras-b941601fcad5\n",
        "    # https://towardsdatascience.com/cnn-transfer-learning-fine-tuning-9f3e7c5806b2\n",
        "\n",
        "    #### Base model\n",
        "    input_shape = (height, width, 3)\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape, pooling = \"max\")\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    #### Model Customization\n",
        "    # We take the last layer of our the model and add it to our classifier\n",
        "    last = base_model.layers[-1].output\n",
        "    x = Flatten()(last)\n",
        "    x = Dense(100, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(num_classes, activation='softmax', name='predictions')(x)\n",
        "    model = Model(base_model.input, x)\n",
        "    # We compile the model\n",
        "    model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_model(model, training_generator, validation_generator, CNN_MODEL_CHECKPOINT):\n",
        "    '''\n",
        "    Fits model, evaluates model, saves best model over epochs and cross-validations.\n",
        "    \n",
        "    Inputs:\n",
        "        model (CNN model) keras.Model object\n",
        "        trainX, trainY (numpy.ndarray) 4D array of DTL features and 2D array of targets for training\n",
        "        testX, testY (numpy.ndarray) 4D array of DTL features and 2D array of targets for testing\n",
        "        current_kfold (int) iteration in kfold cross-val, default=None for no cross-val\n",
        "        display_metrics (bool) Default=False\n",
        "    Returns:\n",
        "        None\n",
        "    # https://towardsdatascience.com/step-by-step-guide-to-using-pretrained-models-in-keras-c9097b647b29\n",
        "    '''\n",
        "\n",
        "    # Use early stopping to help with overfitting\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=False)\n",
        "\n",
        "    # Save best model based on accuracy\n",
        "    mc = ModelCheckpoint(CNN_MODEL_CHECKPOINT, monitor='val_loss', mode='min', \n",
        "                         verbose=True, save_best_only=True)\n",
        "\n",
        "    # Fit model\n",
        "    #history = model.fit(trainX, trainY, \n",
        "    #        epochs=50, \n",
        "    #        batch_size=32, \n",
        "    #        validation_data=(testX, testY), \n",
        "    #        callbacks=[es, mc], \n",
        "    #        verbose=False)\n",
        "    \n",
        "    history = model.fit(x=training_generator,\n",
        "                        validation_data=validation_generator,\n",
        "                        use_multiprocessing=True,\n",
        "                        epochs=50,\n",
        "                        callbacks=[es, mc],\n",
        "                        workers=6)\n",
        "\n",
        "    # Show accuracy\n",
        "    loss, accuracy = model.evaluate(testX, testY, verbose=False)\n",
        "    print(f'                              Accuracy: {accuracy}')\n",
        "\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCS2bGG-CSEu"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06QsEn5BCSEu"
      },
      "source": [
        "SURVEY_NAME = 'DHS'\n",
        "SATELLITE = 'l8'\n",
        "BAND = 'BRGB'\n",
        "TARGET_VAR = 'wealth_index'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkfz8v-lCSEv"
      },
      "source": [
        "### Load Numpy Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFbAlBqwCSEv"
      },
      "source": [
        "# List of npy files\n",
        "NPY_PATH = os.path.join(cf.GOOGLEDRIVE_DIRECTORY, \n",
        "             'Data', \n",
        "             SURVEY_NAME, \n",
        "             'FinalData', \n",
        "             'Individual Datasets',\n",
        "            'cnn_' + SATELLITE,\n",
        "             'npy')\n",
        "\n",
        "NPY_FILES = os.listdir(NPY_PATH)\n",
        "reg = re.compile(r'^' + BAND + '_')                  \n",
        "NPY_FILES = list(filter(reg.search, NPY_FILES)) \n",
        "\n",
        "# List of uids\n",
        "uids = [file.replace('.npy', '').replace(BAND + '_', '') for file in NPY_FILES]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD3TQY6YCSEw"
      },
      "source": [
        "### Prepare Survey Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8CYiA0ICSEw"
      },
      "source": [
        "#### Load survey data\n",
        "survey_df = pd.read_csv(os.path.join(cf.DROPBOX_DIRECTORY, 'Data', SURVEY_NAME, 'FinalData', 'Individual Datasets', 'survey_socioeconomic.csv'))\n",
        "\n",
        "#### Subset survey\n",
        "\n",
        "# Subset if target variable is NA\n",
        "survey_df = survey_df.dropna(axis=0, subset=[TARGET_VAR])\n",
        "\n",
        "# Subset to survey where we have an associated numpy array\n",
        "survey_df = survey_df[survey_df['uid'].isin(uids)]\n",
        "\n",
        "#### Variable Clean/Add\n",
        "\n",
        "# Prep target variable\n",
        "survey_df[TARGET_VAR] = np.round(survey_df[TARGET_VAR]).tolist()\n",
        "survey_df[TARGET_VAR] = survey_df[TARGET_VAR] - 1 # so starts at 0\n",
        "\n",
        "# Add band name\n",
        "survey_df['band_uid'] = BAND + '_' + survey_df['uid']\n",
        "\n",
        "# Indicate Train/Test\n",
        "survey_df['traintest'] = np.random.choice(a = ['train', 'test'], \n",
        "                                      p = [0.8, 0.2],\n",
        "                                      size = survey_df.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewS9TcDXCSEx"
      },
      "source": [
        "### Dictionaries for Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QahhbmFgCSEx"
      },
      "source": [
        "# Partition Dictionary\n",
        "train_uids = survey_df[survey_df.traintest == 'train']['band_uid'].tolist()\n",
        "test_uids = survey_df[survey_df.traintest == 'test']['band_uid'].tolist()\n",
        "\n",
        "partition = {'train': train_uids, \n",
        "             'test': test_uids}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zphi9EFVCSEy"
      },
      "source": [
        "labels = dict(zip(survey_df.band_uid, survey_df[TARGET_VAR]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwArgkPuCSEy"
      },
      "source": [
        "## Implement CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPCLOmoaCSEy"
      },
      "source": [
        "# Parameters\n",
        "params = {'dim': (224,224),\n",
        "          'batch_size': 32,\n",
        "          'n_classes': 5,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], labels, **params)\n",
        "validation_generator = DataGenerator(partition['test'], labels, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU1qcLq6CSEy"
      },
      "source": [
        "CNN_MODEL_PATH = os.path.join('/Users/robmarty/Desktop', f'CNN_DEPVAR.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw4-zEpeCSEy"
      },
      "source": [
        "model = define_model_imagenet(params['dim'][0], params['dim'][1], params['n_classes'])\n",
        "evaluate_model(model, training_generator, validation_generator, CNN_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyWO-cETCSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iV0-Kw8CSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW5j9qIQCSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcipjsxFCSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuIxlPYFCSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a31PEBRnCSEz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZZhx1TvCSE5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kt7NwZDCSE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGyJbYXQCSE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk9ExawtCSE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWHr-JIYCSE6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZezZWLYCSE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_gKDZf5CSE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KVZuvVuCSE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To7jVXgMCSE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7FeCn67CSE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5esgERLICSE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqLU1oQHCSE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWfmyh3zCSE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xDGis2WCSE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gam1tv9CSE8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}