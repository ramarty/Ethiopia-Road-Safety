{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# define paths\n",
    "data_path = '/Users/simonneumeyer/Dropbox/Ethiopia IE - Road Safety/Data/'\n",
    "traffic_path = 'ETRE - Traffic/'\n",
    "traffic_file = 'FinalData/traffic.pq'\n",
    "segment_time_file = 'Time Segment Data/segment_time_panel.pq'\n",
    "\n",
    "# choice of segment granularity BEFORE aggregation (for speeding up purposes) :\n",
    "granularity_km_ex_ante = None\n",
    "granularity_hour_ex_ante = None\n",
    "\n",
    "# choice of segment granularity AT aggregation:\n",
    "granularity_km_ex_post = 1\n",
    "granularity_hour_ex_post = 1\n",
    "\n",
    "# functions\n",
    "\n",
    "def rounder(x, prec=2, base=.05):\n",
    "    return round(base * round(float(x)/base),prec)\n",
    "\n",
    "def datetime_range(start, end, delta):\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        yield current\n",
    "        current += delta\n",
    "\n",
    "def interpolate_row(row):\n",
    "    \"\"\"\n",
    "    This function takes as input a traffic observation (a car entering & exiting the highway at a\n",
    "    specific km and hour), interpolates the time at each kilometer with average speed\n",
    "    and creates and returns a dataframe with all the inferred km-hour combinations as observations\n",
    "    which can then easily be aggregated in the main function.\n",
    "    :param row: a car entering & exiting the highway at a specific km and hour\n",
    "    :return: dataframe with all the inferred km-hour combinations as observations\n",
    "    \"\"\"\n",
    "    # preprocess:\n",
    "    ent_date = datetime.strptime(str(row['ent_occur_time']), \"%Y-%m-%d %H:%M:%S\")\n",
    "    exit_date = datetime.strptime(str(row['trans_occur_time']), \"%Y-%m-%d %H:%M:%S\")\n",
    "    n_km = row['exit_km'] - row['entrance_km']\n",
    "\n",
    "    # create seconds per kilometer variable to interpolate the time at each kilometer:\n",
    "    speed_sec_km = (exit_date - ent_date).total_seconds() / abs(n_km)\n",
    "    speed_sec_km = math.floor(speed_sec_km)\n",
    "\n",
    "    new_index = [pd.to_datetime(dt.strftime(\"%Y-%m-%d %H:%M:%S\")) for dt in\n",
    "                 datetime_range(ent_date, exit_date, timedelta(seconds=speed_sec_km))]\n",
    "\n",
    "    # define step direction (for when entrance_km > exit_km) for km_count:\n",
    "    step_direction = int(n_km / abs(n_km))\n",
    "    km_count = [j for j in range(int(row['entrance_km']), int(row['exit_km'] + step_direction), step_direction)]\n",
    "\n",
    "    # create new dataframe to conduct aggregation on later:\n",
    "    dt_one = pd.DataFrame(km_count, index=new_index[:len(km_count)], columns=['km'])\n",
    "    dt_one['hour'] = dt_one.index.hour\n",
    "    dt_one['year'] = dt_one.index.year\n",
    "    dt_one['month'] = dt_one.index.month\n",
    "    dt_one['day'] = dt_one.index.day\n",
    "    dt_one['tstamp'] = pd.to_datetime(dt_one[['year', 'month', 'day']])\n",
    "    dt_one['direction'] = row['direction']\n",
    "    dt_one['cars'] = oversampling_factor * row['cars']\n",
    "    dt_one['total_weight'] = oversampling_factor * row['total_weight']\n",
    "    dt_one['speed_km_hr'] = oversampling_factor * row['speed_km_hr']\n",
    "    dt_one['speed_sec_km'] = oversampling_factor * speed_sec_km\n",
    "    \n",
    "    for i in range(1,8):\n",
    "        dt_one[f'veh_type_{i}'] = oversampling_factor * row[f'veh_type_{i}']\n",
    "    \n",
    "    \n",
    "    dt_one_tr = dt_one.set_index(['tstamp', 'hour', 'km', 'direction'])[['cars', 'total_weight', 'speed_km_hr',\n",
    "                                                                       'veh_type_1', 'veh_type_2', 'veh_type_3',\n",
    "                                                                       'veh_type_4', 'veh_type_5', 'veh_type_6',\n",
    "                                                                       'veh_type_7', 'speed_sec_km']]\n",
    "    \n",
    "    return dt_one_tr\n",
    "\n",
    "def main(data, frac):\n",
    "    \"\"\"\n",
    "    This function does 3 things:\n",
    "    1. Performs, if needed, undersampling of the traffic file\n",
    "    2. Performs the interpolate_row function on every row of the traffic dataset\n",
    "        and concatenates the outputs.\n",
    "    3. Aggregates the number of cars by hour & km to return the final traffic feature\n",
    "    :param data: traffic data\n",
    "    :param frac: fraction of random sample of traffic data\n",
    "    :return: traffic feature dataframe\n",
    "    \"\"\"\n",
    "    # Run over a random subset of the data:\n",
    "    if frac is not None:\n",
    "        data = data.sample(frac=frac)\n",
    "        data = data.reset_index()\n",
    "    data_dict = {}\n",
    "    tic = time.time()\n",
    "    for i in data.index:\n",
    "        if i%1000==0:\n",
    "            toc = time.time()\n",
    "            print(f'{round(i/len(data)*100,2)}% done, {round(toc-tic,2)} seconds')\n",
    "            tic = toc\n",
    "\n",
    "        data_dict[i] = interpolate_row(data.loc[i, :])\n",
    "        \n",
    "    traffic = pd.concat(data_dict, axis=0, names=['car', 'tstamp', 'hour', 'km', 'direction'])\n",
    "#    traffic = pd.concat(\n",
    "#        {\n",
    "#            i: interpolate_row(data.loc[i, :]) for i in data.index\n",
    "#        }, axis=0, names=['car', 'tstamp', 'hour', 'km', 'direction'])\n",
    "\n",
    "    # ex post aggregation if needed:    \n",
    "    traffic = traffic.reset_index()\n",
    "    \n",
    "    if granularity_km_ex_post is not None:\n",
    "        traffic['km'] = traffic.km.apply(lambda x: rounder(x, prec=2, base=granularity_km_ex_post))\n",
    "    if granularity_hour_ex_post is not None:\n",
    "        traffic['hour'] = traffic.hour.apply(lambda x: rounder(x, prec=2, base=granularity_hour_ex_post))\n",
    "    \n",
    "    traffic = traffic.set_index(['tstamp', 'hour', 'km', 'direction'])[['cars', 'total_weight', 'speed_km_hr',\n",
    "                                                                       'veh_type_1', 'veh_type_2', 'veh_type_3',\n",
    "                                                                       'veh_type_4', 'veh_type_5', 'veh_type_6',\n",
    "                                                                       'veh_type_7', 'speed_sec_km']]\n",
    "\n",
    "    results = traffic.groupby(['tstamp', 'hour', 'km', 'direction']).sum()\n",
    "    \n",
    "    results = results.reset_index()\n",
    "    # to get the average weight and speed: divide the totals by the amount of cars:\n",
    "    cols_to_divide = ['total_weight', 'speed_km_hr', 'speed_sec_km']\n",
    "    for col in cols_to_divide:\n",
    "        results[col] = results[col] / results['cars']\n",
    "\n",
    "    # compute ratio of each vehicle type:\n",
    "    cols_to_sum = [f'veh_type_{i}' for i in range(1,8)]\n",
    "    results['veh_type_total'] = results[cols_to_sum].sum(axis=1)\n",
    "    for col in cols_to_sum:     \n",
    "        results[col] = results[col] / results['veh_type_total']\n",
    "    results = results.drop(columns=['veh_type_total'])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 8min 30s, total: 13min 16s\n",
      "Wall time: 28min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load data:\n",
    "traffic_final = pd.read_parquet(data_path + traffic_path + traffic_file, engine='pyarrow')\n",
    "time_segment = pd.read_parquet(data_path + segment_time_file, engine='pyarrow')\n",
    "\n",
    "# preprocess\n",
    "# formatting:\n",
    "traffic_final.ent_occur_time = pd.to_datetime(traffic_final.ent_occur_time)\n",
    "traffic_final.trans_occur_time = pd.to_datetime(traffic_final.trans_occur_time)\n",
    "\n",
    "# dropping rows where exit_km = entrance_km (0.01% of the data)\n",
    "traffic_final = traffic_final[traffic_final.entrance_km != traffic_final.exit_km]\n",
    "\n",
    "# drop timestamp NAs:\n",
    "traffic_final = traffic_final.dropna(subset=['ent_occur_time', 'trans_occur_time'])\n",
    "traffic_final = traffic_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 26s, sys: 14.7 s, total: 4min 40s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# consider only the relevant variables:\n",
    "traffic_final = traffic_final[['ent_occur_time', 'trans_occur_time', 'entrance_km', \n",
    "                               'exit_km', 'direction', 'total_weight', 'veh_type', 'speed_km_hr']]\n",
    "\n",
    "# kick out rows where exit time is before entrance time or less then 1 min after:\n",
    "index_to_keep = [i for i, x in enumerate(traffic_final.trans_occur_time-traffic_final.ent_occur_time) if x.total_seconds() > 60]\n",
    "traffic_final = traffic_final.loc[index_to_keep, :]\n",
    "traffic_final = traffic_final.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.7 s, sys: 3.44 s, total: 26.2 s\n",
      "Wall time: 29.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# preliminary aggregation for efficiency purposes:\n",
    "traffic_final['ent_date'] = traffic_final.ent_occur_time.dt.date\n",
    "traffic_final['ent_hour'] = traffic_final.ent_occur_time.dt.hour\n",
    "traffic_final['exit_date'] = traffic_final.trans_occur_time.dt.date\n",
    "traffic_final['exit_hour'] = traffic_final.trans_occur_time.dt.hour\n",
    "traffic_final['cars'] = 1\n",
    "\n",
    "# round to choice of segment & time granularity level before aggregation:\n",
    "if granularity_km_ex_ante is not None:\n",
    "    traffic_final['entrance_km'] = traffic_final.entrance_km.apply(lambda x: rounder(x, prec=2, base=granularity_km_ex_ante))\n",
    "    traffic_final['exit_km'] = traffic_final.exit_km.apply(lambda x: rounder(x, prec=2, base=granularity_km_ex_ante))\n",
    "    \n",
    "if granularity_hour_ex_ante is not None:\n",
    "    traffic_final['ent_hour'] = traffic_final.ent_hour.apply(lambda x: rounder(x, prec=2, base=granularity_hour_ex_ante))\n",
    "    traffic_final['exit_hour'] = traffic_final.exit_hour.apply(lambda x: rounder(x, prec=2, base=granularity_hour_ex_ante)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ex ante aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 34s, sys: 52 s, total: 4min 26s\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# vehicle type aggregation:\n",
    "veh_type_pct = traffic_final.groupby(['ent_date', 'ent_hour', 'exit_date', 'exit_hour', 'entrance_km', \n",
    "                                      'exit_km', 'direction'\n",
    "                      ])['veh_type'].value_counts(dropna=False)\n",
    "veh_type_pct = veh_type_pct.unstack(fill_value=0)\n",
    "veh_type_pct = veh_type_pct.rename(columns={i: f'veh_type_{i}' for i in range(1,8)})\n",
    "\n",
    "# cars, total_weight and speed aggregation: \n",
    "# First by summing, later (when assigned to kilometer and time) total_weight and speed will be divided \n",
    "# by total amount of cars.\n",
    "traffic_final = traffic_final.groupby(['ent_date', 'ent_hour', 'exit_date', 'exit_hour', 'entrance_km', \n",
    "                                       'exit_km', 'direction'\n",
    "                      ])['cars', 'total_weight', 'speed_km_hr'].sum() # might fail!\n",
    "\n",
    "# merge the two:\n",
    "traffic_final = traffic_final.merge(veh_type_pct, how='left', left_index=True, right_index=True, validate='one_to_one')\n",
    "\n",
    "traffic_final = traffic_final.reset_index()\n",
    "\n",
    "# combine hours and date:\n",
    "traffic_final['ent_occur_time'] = pd.to_datetime(traffic_final['ent_date']) + pd.to_timedelta(traffic_final['ent_hour'], unit='hr')\n",
    "traffic_final['trans_occur_time'] = pd.to_datetime(traffic_final['exit_date']) + pd.to_timedelta(traffic_final['exit_hour'], unit='hr')\n",
    "\n",
    "# adding 30 mins to all dates to keep aggregation more accurate \n",
    "# (exception: when both timestamps are equal, ent_time only moved 15 mins):\n",
    "traffic_final['ent_occur_time'] = traffic_final.apply(lambda x: x['ent_occur_time'] + timedelta(minutes=15) if x['trans_occur_time']==x['ent_occur_time'] else x['ent_occur_time'] + timedelta(minutes=30), axis=1)\n",
    "traffic_final['trans_occur_time'] = traffic_final.trans_occur_time.apply(lambda x: x + timedelta(minutes=30))\n",
    "\n",
    "# testing whether it worked:\n",
    "assert len(traffic_final[traffic_final.trans_occur_time==traffic_final.ent_occur_time])==0\n",
    "\n",
    "# drop redundant columns:\n",
    "traffic_final = traffic_final.drop(['ent_date', 'ent_hour', 'exit_date', 'exit_hour'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run main:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% done\n",
      "0.0 seconds\n",
      "0.1% done\n",
      "28.13 seconds\n",
      "0.19% done\n",
      "31.86 seconds\n",
      "0.29% done\n",
      "32.44 seconds\n",
      "0.39% done\n",
      "32.04 seconds\n",
      "0.48% done\n",
      "32.89 seconds\n",
      "0.58% done\n",
      "37.17 seconds\n",
      "0.67% done\n",
      "33.37 seconds\n",
      "0.77% done\n",
      "31.25 seconds\n",
      "0.87% done\n",
      "31.63 seconds\n",
      "0.96% done\n",
      "35.32 seconds\n",
      "1.06% done\n",
      "31.04 seconds\n",
      "1.16% done\n",
      "37.98 seconds\n",
      "1.25% done\n",
      "33.13 seconds\n",
      "1.35% done\n",
      "32.69 seconds\n",
      "1.44% done\n",
      "32.79 seconds\n",
      "1.54% done\n",
      "32.34 seconds\n",
      "1.64% done\n",
      "32.81 seconds\n",
      "1.73% done\n",
      "34.66 seconds\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# run the main function:\n",
    "oversampling_factor = 2\n",
    "result = main(traffic_final, frac=1/oversampling_factor)\n",
    "\n",
    "#result.to_parquet(data_path + 'Time Segment Data/traffic_feature.pq')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
